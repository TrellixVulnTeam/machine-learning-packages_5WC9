{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNj6U2A76jpf"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import traceback\n",
    "import shutil\n",
    "import logging\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.tensorboard as tb\n",
    "\n",
    "from runners.diffusion import Diffusion\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "\n",
    "def parse_args_and_config():\n",
    "    parser = argparse.ArgumentParser(description=globals()[\"__doc__\"])\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--config\", type=str, required=True, help=\"Path to the config file\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=1234, help=\"Random seed\")\n",
    "    parser.add_argument(\n",
    "        \"--exp\", type=str, default=\"exp\", help=\"Path for saving running related data.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--doc\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"A string for documentation purpose. \"\n",
    "        \"Will be the name of the log folder.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--comment\", type=str, default=\"\", help=\"A string for experiment comment\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verbose\",\n",
    "        type=str,\n",
    "        default=\"info\",\n",
    "        help=\"Verbose level: info | debug | warning | critical\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to produce samples from the model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--image_folder\",\n",
    "        type=str,\n",
    "        default=\"images\",\n",
    "        help=\"The folder name of samples\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ni\",\n",
    "        action=\"store_true\",\n",
    "        help=\"No interaction. Suitable for Slurm Job launcher\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--timesteps\", type=int, default=1000, help=\"number of steps involved\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--deg\", type=str, required=True, help=\"Degradation\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sigma_0\", type=float, required=True, help=\"Sigma_0\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eta\", type=float, default=0.85, help=\"Eta\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--etaB\", type=float, default=1, help=\"Eta_b (before)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--subset_start', type=int, default=-1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--subset_end', type=int, default=-1\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.log_path = os.path.join(args.exp, \"logs\", args.doc)\n",
    "\n",
    "    # parse config file\n",
    "    with open(os.path.join(\"configs\", args.config), \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    new_config = dict2namespace(config)\n",
    "\n",
    "    tb_path = os.path.join(args.exp, \"tensorboard\", args.doc)\n",
    "\n",
    "    level = getattr(logging, args.verbose.upper(), None)\n",
    "    if not isinstance(level, int):\n",
    "        raise ValueError(\"level {} not supported\".format(args.verbose))\n",
    "\n",
    "    handler1 = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(levelname)s - %(filename)s - %(asctime)s - %(message)s\"\n",
    "    )\n",
    "    handler1.setFormatter(formatter)\n",
    "    logger = logging.getLogger()\n",
    "    logger.addHandler(handler1)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    os.makedirs(os.path.join(args.exp, \"image_samples\"), exist_ok=True)\n",
    "    args.image_folder = os.path.join(\n",
    "        args.exp, \"image_samples\", args.image_folder\n",
    "    )\n",
    "    if not os.path.exists(args.image_folder):\n",
    "        os.makedirs(args.image_folder)\n",
    "    else:\n",
    "        overwrite = False\n",
    "        if args.ni:\n",
    "            overwrite = True\n",
    "        else:\n",
    "            response = input(\n",
    "                f\"Image folder {args.image_folder} already exists. Overwrite? (Y/N)\"\n",
    "            )\n",
    "            if response.upper() == \"Y\":\n",
    "                overwrite = True\n",
    "\n",
    "        if overwrite:\n",
    "            shutil.rmtree(args.image_folder)\n",
    "            os.makedirs(args.image_folder)\n",
    "        else:\n",
    "            print(\"Output image folder exists. Program halted.\")\n",
    "            sys.exit(0)\n",
    "\n",
    "    # add device\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    logging.info(\"Using device: {}\".format(device))\n",
    "    new_config.device = device\n",
    "\n",
    "    # set random seed\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    return args, new_config\n",
    "\n",
    "\n",
    "def dict2namespace(config):\n",
    "    namespace = argparse.Namespace()\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            new_value = dict2namespace(value)\n",
    "        else:\n",
    "            new_value = value\n",
    "        setattr(namespace, key, new_value)\n",
    "    return namespace\n",
    "\n",
    "\n",
    "def main():\n",
    "    args, config = parse_args_and_config()\n",
    "    logging.info(\"Writing log file to {}\".format(args.log_path))\n",
    "    logging.info(\"Exp instance id = {}\".format(os.getpid()))\n",
    "    logging.info(\"Exp comment = {}\".format(args.comment))\n",
    "\n",
    "    try:\n",
    "        runner = Diffusion(args, config)\n",
    "        runner.sample()\n",
    "    except Exception:\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5270,
     "status": "ok",
     "timestamp": 1654114882041,
     "user": {
      "displayName": "Malek Ibrahim",
      "userId": "16616577075798638819"
     },
     "user_tz": 300
    },
    "id": "ftSFJ7Ta66t3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NstGboCx7cCP"
   },
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    This matches the implementation in Denoising Diffusion Probabilistic Models:\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "    return emb\n",
    "\n",
    "\n",
    "def nonlinearity(x):\n",
    "    # swish\n",
    "    return x*torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def Normalize(in_channels):\n",
    "    return torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if self.with_conv:\n",
    "            self.conv = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(\n",
    "            x, scale_factor=2.0, mode=\"nearest\")\n",
    "        if self.with_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if self.with_conv:\n",
    "            # no asymmetric padding in torch conv, must do it ourselves\n",
    "            self.conv = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=2,\n",
    "                                        padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.with_conv:\n",
    "            pad = (0, 1, 0, 1)\n",
    "            x = torch.nn.functional.pad(x, pad, mode=\"constant\", value=0)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n",
    "                 dropout, temb_channels=512):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        out_channels = in_channels if out_channels is None else out_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_conv_shortcut = conv_shortcut\n",
    "\n",
    "        self.norm1 = Normalize(in_channels)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)\n",
    "        self.temb_proj = torch.nn.Linear(temb_channels,\n",
    "                                         out_channels)\n",
    "        self.norm2 = Normalize(out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)\n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                self.conv_shortcut = torch.nn.Conv2d(in_channels,\n",
    "                                                     out_channels,\n",
    "                                                     kernel_size=3,\n",
    "                                                     stride=1,\n",
    "                                                     padding=1)\n",
    "            else:\n",
    "                self.nin_shortcut = torch.nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=1,\n",
    "                                                    padding=0)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = x\n",
    "        h = self.norm1(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        h = h + self.temb_proj(nonlinearity(temb))[:, :, None, None]\n",
    "\n",
    "        h = self.norm2(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                x = self.conv_shortcut(x)\n",
    "            else:\n",
    "                x = self.nin_shortcut(x)\n",
    "\n",
    "        return x+h\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.norm = Normalize(in_channels)\n",
    "        self.q = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.k = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.v = torch.nn.Conv2d(in_channels,\n",
    "                                 in_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 padding=0)\n",
    "        self.proj_out = torch.nn.Conv2d(in_channels,\n",
    "                                        in_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=1,\n",
    "                                        padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = x\n",
    "        h_ = self.norm(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "\n",
    "        # compute attention\n",
    "        b, c, h, w = q.shape\n",
    "        q = q.reshape(b, c, h*w)\n",
    "        q = q.permute(0, 2, 1)   # b,hw,c\n",
    "        k = k.reshape(b, c, h*w)  # b,c,hw\n",
    "        w_ = torch.bmm(q, k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n",
    "        w_ = w_ * (int(c)**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_, dim=2)\n",
    "\n",
    "        # attend to values\n",
    "        v = v.reshape(b, c, h*w)\n",
    "        w_ = w_.permute(0, 2, 1)   # b,hw,hw (first hw of k, second of q)\n",
    "        # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n",
    "        h_ = torch.bmm(v, w_)\n",
    "        h_ = h_.reshape(b, c, h, w)\n",
    "\n",
    "        h_ = self.proj_out(h_)\n",
    "\n",
    "        return x+h_\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        ch, out_ch, ch_mult = config.model.ch, config.model.out_ch, tuple(config.model.ch_mult)\n",
    "        num_res_blocks = config.model.num_res_blocks\n",
    "        attn_resolutions = config.model.attn_resolutions\n",
    "        dropout = config.model.dropout\n",
    "        in_channels = config.model.in_channels\n",
    "        resolution = config.data.image_size\n",
    "        resamp_with_conv = config.model.resamp_with_conv\n",
    "        num_timesteps = config.diffusion.num_diffusion_timesteps\n",
    "        \n",
    "        if config.model.type == 'bayesian':\n",
    "            self.logvar = nn.Parameter(torch.zeros(num_timesteps))\n",
    "        \n",
    "        self.ch = ch\n",
    "        self.temb_ch = self.ch*4\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.resolution = resolution\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # timestep embedding\n",
    "        self.temb = nn.Module()\n",
    "        self.temb.dense = nn.ModuleList([\n",
    "            torch.nn.Linear(self.ch,\n",
    "                            self.temb_ch),\n",
    "            torch.nn.Linear(self.temb_ch,\n",
    "                            self.temb_ch),\n",
    "        ])\n",
    "\n",
    "        # downsampling\n",
    "        self.conv_in = torch.nn.Conv2d(in_channels,\n",
    "                                       self.ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)\n",
    "\n",
    "        curr_res = resolution\n",
    "        in_ch_mult = (1,)+ch_mult\n",
    "        self.down = nn.ModuleList()\n",
    "        block_in = None\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_in = ch*in_ch_mult[i_level]\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                block.append(ResnetBlock(in_channels=block_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(AttnBlock(block_in))\n",
    "            down = nn.Module()\n",
    "            down.block = block\n",
    "            down.attn = attn\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                down.downsample = Downsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res // 2\n",
    "            self.down.append(down)\n",
    "\n",
    "        # middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        self.mid.attn_1 = AttnBlock(block_in)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "\n",
    "        # upsampling\n",
    "        self.up = nn.ModuleList()\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            skip_in = ch*ch_mult[i_level]\n",
    "            for i_block in range(self.num_res_blocks+1):\n",
    "                if i_block == self.num_res_blocks:\n",
    "                    skip_in = ch*in_ch_mult[i_level]\n",
    "                block.append(ResnetBlock(in_channels=block_in+skip_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(AttnBlock(block_in))\n",
    "            up = nn.Module()\n",
    "            up.block = block\n",
    "            up.attn = attn\n",
    "            if i_level != 0:\n",
    "                up.upsample = Upsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res * 2\n",
    "            self.up.insert(0, up)  # prepend to get consistent order\n",
    "\n",
    "        # end\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = torch.nn.Conv2d(block_in,\n",
    "                                        out_ch,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        assert x.shape[2] == x.shape[3] == self.resolution\n",
    "\n",
    "        # timestep embedding\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = self.temb.dense[0](temb)\n",
    "        temb = nonlinearity(temb)\n",
    "        temb = self.temb.dense[1](temb)\n",
    "\n",
    "        # downsampling\n",
    "        hs = [self.conv_in(x)]\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                h = self.down[i_level].block[i_block](hs[-1], temb)\n",
    "                if len(self.down[i_level].attn) > 0:\n",
    "                    h = self.down[i_level].attn[i_block](h)\n",
    "                hs.append(h)\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                hs.append(self.down[i_level].downsample(hs[-1]))\n",
    "\n",
    "        # middle\n",
    "        h = hs[-1]\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "\n",
    "        # upsampling\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            for i_block in range(self.num_res_blocks+1):\n",
    "                h = self.up[i_level].block[i_block](\n",
    "                    torch.cat([h, hs.pop()], dim=1), temb)\n",
    "                if len(self.up[i_level].attn) > 0:\n",
    "                    h = self.up[i_level].attn[i_block](h)\n",
    "            if i_level != 0:\n",
    "                h = self.up[i_level].upsample(h)\n",
    "\n",
    "        # end\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        return h"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0rnRGWNAKFOkY+hY7Sf51",
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
